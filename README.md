# Финальный проект по курсу «Цифровая архивация современности»
Данный репозиторий содержит коллекцию из четырёх веб-сайтов, собранных с использованием [wpull](https://wpull.readthedocs.io/en/master/). В репозитории опубликованы следующие материалы по каждому сайту коллекции:
- Метаданные, полученные инструментом [metawarc](https://github.com/datacoon/metawarc). Включают в себя полные HTTP-заголовки, MIME-типы контента, статус-коды ответов и технические характеристики
- Базы данных с индексацией всех собранных ресурсов
- Ссылки на дополнительные материалы, связанные с коллекцией и процессом архивации
- Результаты анализа архивируемости, полученные с помощью сервиса [ArchiveReady](https://archiveready.com/), включающие индекс архивируемости и детальные показатели сохранения цифрового контента

## Краткое описание коллекции
В коллекцию вошло несколько сайтов:
1. [Dave Cheney](https://dave.cheney.net/) (технический блог одного из ключевых разработчиков языка Go)
2. [django](https://www.djangoproject.com/) (официальный сайт веб-фреймворка Django на Python)
3. [Максим Дунаевский](https://dunaevsky.iz.ru/) (тематический спецпроект, посвященный творчеству композитора)
4. [Never Ending Voyage](https://www.neverendingvoyage.com/) (блог о путешествиях и цифровом кочевничестве)

Коллекция разноплановая, поскольку хотелось посмотреть на работу инструментов в разнообразии тематик.
Технические ресурсы, такие как блог Дейва Чейни и документация Django, представляют собой живую историю развития технологий, записи мыслительных процессов, ошибок.  Их исчезновение означало бы потерю контекста, в котором рождались ключевые для современной IT-инфраструктуры инструменты и языки программирования.

Вся коллекция содержит файлы следующих форматов: html, json, js, css, img/png, txt, pdf.

## Метод и технологии 
В процессе создания коллекции применялся комплекс инструментов для сбора, воспроизведения, анализа и обработки веб-архивов.

Основным инструментом для сбора архивов выступила библиотека wpull, доступная для Python версии ниже 3.7. Она позволяет создавать локальные копии сайтов с детальной настройкой параметров, таких как глубина рекурсии, таймауты и включение метаданных архиватора.
После сбора архивов их воспроизводимость была проверена с помощью сервиса ReplayWeb.page, который позволяет визуализировать и интерактивно просматривать сохранённые веб-страницы.
Для оценки качества полученных материалов применялся онлайн-сервис ArchiveReady. Он определяет индекс архивируемости сайтов и детально анализирует различные показатели, влияющие на успешность их долгосрочного сохранения.
Завершающий этап работы включал анализ и извлечение метаданных. Для этого использовалась утилита командной строки metawarc, которая позволяет исследовать WARC-файлы, получать структурированные метаданные и выполнять операции на их основе, создавая тем самым индексные базы данных для каждого архива.

## Структура проекта
Отдельные папки, названные в соответствии с адресами сайтов, вошедших в коллекцию. Внутри папок:
README.md – описание сайта, результаты обработки его архива по перечисленным в разделе «Метод и технологии» методам
[название сайта]_meta.jsonl – метаданные архива, собранные с помощью metawarc
metadata[название].txt – метаданные, собранные при помощи metawarc metadata
replaywebpage.png – скриншот архива, открытого на сайте Replay webpage
archiveready.png – скриншот саммари анализа архивируемости архива, проведённого при помощи сервиса ArchiveReady
README.md – описание проекта

## Контакты
Автор проекта - [Кузнецова Елена](https://github.com/kultyaa)

## Условия использования
Материалы проекта (за исключением архивов и содержимого сайтов) могут использоваться и распространяться в соответствии с лицензией Creative Commons BY 4.0.
